export NGPU=2; python -m torch.distributed.launch --nproc_per_node=$NGPU train.py --exp_name unsupMT_enpt \
--dump_path ./dumped/ \
--reload_model 'mlm_17_1280.pth,mlm_17_1280.pth' \
--data_path ./data-en-pt/processed/en-pt/ \
--lgs 'fr-de-tr-pl-vi-ar-zh-pt-it-ja-nl-hi-es-en-sv-ko-ru' \
--ae_steps 'en,pt' \
--bt_steps 'en-pt-en,pt-en-pt' \
--word_shuffle 3 \
--word_dropout 0.1 \
--word_blank 0.1  \
--lambda_ae '0:1,100000:0.1,300000:0' \
--encoder_only false  \
--emb_dim 1280  \
--max_vocab 200000 \
--use_lang_emb false \
--save_periodic -1 \
--n_layers 16 \
--n_heads 16  \
--dropout 0.1  \
--attention_dropout 0.1  \
--gelu_activation true \
--tokens_per_batch 2000  \
--batch_size 32  \
--bptt 256  \
--optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001  \
--epoch_size 200000  \
--eval_bleu true \
--stopping_criterion 'valid_en-pt_mt_bleu,10' \
--validation_metrics 'valid_en-pt_mt_bleu'
